## 3-11. Tsunami Risk Reduction: Are We Better Prepared Today Than in 2004?

*/Finn Løvholt, Carl B. Harbitz, Farrokh Nadim (Norwegian Geotechnical Institute); Joern Birkmann, Neysa J. Setiadi, Claudia Bach (UNU-EHS); Nishara Fernando (University of Colombo)/*

The Indian Ocean tsunami of December 26, 2004, which was responsible for over 220,000 deaths, remains one of the deadliest disasters triggered by a natural hazard event (MunichRe 2013). It demonstrated the need for more research, improved planning activities, awareness raising, and early warning systems (UNISDR 2005). It also provided important lessons for developing the HFA and sharpened the commitment for its implementation (UNISDR 2009). 

In hindsight, the 2004 Indian Ocean tsunami should not have come as a surprise (Satake and Atwater 2007). Events occurring two centuries ago provided a warning sign that was remarked by scientists a short time before the disaster hit (Cummins and Leonard 2004). Recent paleotsunami deposits provide evidence for past events in prehistorical times (Jankaew et al. 2008). The 2004 Indian Ocean tsunami did introduce a paradigm change in the sense that previous models for constraining earthquake magnitudes along fault zones are now refuted (Stein and Okal 2007). As a consequence, mega-thrust earthquakes emerging from any of the large subduction zones in the world could no longer be ruled out.  

The tsunamis that hit the Mentawai Islands in 2010 and Japan in 2011 also revealed weaknesses in the way society deals with tsunami hazard. The 2011 Tohoku tsunami was stronger than the design standards of the tsunami barriers (Cyranowski 2011), and it revealed inadequacies in the Japanese hazard maps, which were largely based on historical earthquake records limiting the earthquake moment magnitude to about 8, one order of magnitude lower than the 2011 event (Geller 2011). Recent analyses have shown that a tsunami of this size may have a return period of about 500 years and should not have been a surprise (Kagan and Jackson 2013).

Today, from a scientific point of view, many of the tools for tsunami risk assessment are available, but it remains unclear whether they are actually used in national and regional DRM efforts. This case study reviews the application of DRM methodologies for tsunami risk, with a focus on Southeast Asia, and in particular Indonesia and Sri Lanka, which were severely affected by the 2004 Indian Ocean tsunami.  

///Progress in tsunami hazard assessment///. Before the Indian Ocean tsunami occurred, and for a few years afterward, tsunami hazard assessment was mainly based on worst-case scenario analysis. As tsunamis having long return periods are believed to dominate the risk (Nadim and Glade 2006), the worst-case-scenario approaches may sometimes be appropriate, given the large uncertainty linked to events having return periods of hundreds or even thousands of years. Furthermore, such scenarios are often useful in areas that have a complex tectonic or geological setting, and that lack the information needed to conduct a proper probabilistic analysis (Løvholt et al. 2012a).

The common metric associated with tsunami hazard is usually the run-up height of the tsunami along a coastline. However, other metrics should be considered. The Tsunami Pilot Study Working Group (2006) lists the following tsunami impact metrics (intensity measures) that may be entered as parameters in tsunami models for assessment of mortality, building damage, and forces on structures: tsunami flow depth; wave current speed; wave current acceleration; wave current inertia component (product of acceleration and flow depth); and momentum flux (product of squared wave current speed and flow depth and in many circumstances the best damage indicator).

For hazard assessments, tsunami hazard modellers take different approaches (even if all consider a worst-case scenario), and assessments typically rely on different data sources for topography, bathymetry, and/or seismicity. These differences can result in users being provided with multiple different tsunami hazard maps by different entities, as is described in box 3-5. There is also a growing recognition of the limitations of tsunami hazard mapping in areas with coarse resolution digital elevation and bathymetry data sets; see box 2-4 for discussion of this challenge.

Over the last decade, probabilistic methods for estimating tsunami hazard have become increasingly available. One important approach is the Probabilistic Tsunami Hazard Assessment (PTHA) method, which is largely based on the well-documented approach to probabilistic seismic hazard analysis originally proposed by Cornell (1968). In recent years, PTHA has been used to quantify tsunami risk in a number of areas, including Japan, Australia, the West Coast of the United States, and the Mediterranean (Annaka et al. 2007; Burbidge et al. 2008; Parsons and Geist 2009; Gonzalez et al. 2009; Thio, Somerville, and Polet 2010; Sørensen et al. 2012). 
A crucial element in PTHA is the estimation of the frequency of occurrence and maximum magnitudes of large tsunami-generating earthquakes in each source region. As the historical record for mega-thrusts and other large earthquakes is very short relative to their long recurrence times, it is not possible to constrain the occurrence and maximum magnitudes of intense tsunamigenic earthquakes directly using observed seismicity. Recent events such as the large 2004 Indian Ocean tsunami and the 2011 Tohoku tsunami demonstrate the reality of tsunami risk. Past mega-thrust events along other faults zones (such as those in 1960 in Chile and 1964 in Alaska) provide additional reminders of the need for precautionary actions. 

///Progress in understanding exposure to tsunamis///. Mapping exposure in various hazard zones exploits remote sensing data, geo-information systems, and existing data for population, buildings, critical facilities, etc. Population data are typically obtained from available statistical data (population census) at the lowest administrative level, while data at the building level is normally obtained through remote sensing analysis (e.g., Taubenböck et al. 2008). (A more detailed description of exposure data collection is in part 2 above.) 

In Padang the approach to exposure also considered population groups with different evacuation (physical) capabilities. The data included an activity diary that was part of household surveys, as well as local statistics and building data from remote sensing (Setiadi et al. 2010). The analysis emphasized differentiated exposure related to the spatial distribution of the city functions (building uses) and characteristics of the population, and included factors such as work activities, gender, and income groups (Setiadi 2014).

Progress in understanding and assessing vulnerability to tsunamis. Vulnerability is a multifaceted concept that has different definitions depending on the context and discipline. In natural sciences and engineering, vulnerability often refers to the physical vulnerability of the exposed population or elements at risk. Few reliable models of physical vulnerability to tsunamis currently exist, though substantial progress toward such models is being made. 

In social sciences, the term vulnerability refers to societal vulnerability, which is related to a society’s exposure, susceptibility, and fragility, as well its capacity to react to a hazardous event. A fair amount of progress has been made in recent years in understanding the factors that influence societal vulnerability and in developing relevant assessment methodologies. For example, important vulnerability factors were revealed by the Indian Ocean tsunami in 2004, which devastated Indonesia’s Aceh Province and many coastal districts of Sri Lanka. The especially high number of victims was due to the near absence of preparedness measures appropriate for such an extreme event. 

Populations need to be educated about tsunamis and to be aware of hazard zones if evacuations are to be safe and effective. There was little knowledge of tsunamis in the affected areas in Indonesia and Sri Lanka prior to the 2004 tsunami. An Asian Disaster Reduction Center survey (ADRC 2006) conducted in October–December 2005 showed that most of the Aceh population (88.50 percent) had never heard of tsunamis before the 2004 event. The others (11.50 percent) said that they had heard of a big sea wave coming to land (recounted in Islamic storytelling) from family, friends, books, school, or television. In Sri Lanka, less than 10 percent of respondents reported having had any knowledge about tsunamis before 2004 (Jayasinghem and Birkmann 2007). This lack of knowledge led to what was identified as a main reason for the high number of fatalities: a lack of preparedness for such an extreme event (Amarasinghe 2007). In addition, many people ran to the beach to watch the setback of the sea (Amarasinghe 2007). 

///Gaps and recommendations///. In the actual planning of tsunami risk reduction activities, limited use of hazard information (hazard maps) for buffer zones and evacuation maps was identified. More advanced methodologies encompassing vulnerability factors have not been fully integrated into risk management activities. Continuous monitoring of vulnerability to tsunamis is hampered by the lack of a centralized database, absence of information sharing among different agencies and local and regional institutions, and lack of standardized common guidelines on tsunami vulnerability assessment. Furthermore, tsunami risk reduction planning tends to focus on hard measures—for example, physical construction of evacuation shelters—but seldom considers soft measure, such as evacuation behavior and utilization of facilities. Second-order vulnerabilities (in the case of relocation) also call for a detailed analysis and careful implementation of DRM, taking into account factors like the lack of land title and information about resettlement decisions.

While from a methodological perspective, important progress has been made in the last decade, the new methodologies are not widely applied in practice. Hazard maps, for example, are too often used only for establishing buffer zones when they could also aid in planning of construction and development and in determining evacuation routes. More work is needed to develop indicators and criteria that determine the use of vulnerability information in DRM, as well as to assess the effectiveness of key strategies and tools (like people-centered early warning systems). These indicators and criteria will ensure the application of the most recent findings on disaster risk and assist in choosing the appropriate risk reduction strategies.
